{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/pz413sz/Desktop/test_workflows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow import r_0_0_read_sns_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This module contains practice data available to us\n",
      "Seaborn data: anscombe, attention, brain_networks, car_crashes, diamonds, dots\n",
      "Seaborn data: exercise, flights, fmri, gammas, iris, mpg, planets, tips, titanic\n",
      "scikitlearn available datasets are:\n",
      "load_boston(), load_iris(), load_diabetes(), load_linnerud()\n",
      "available_sns_data() to look at seaborn data available\n",
      "sns_data(data=\"tips\") -> to get sns data\n",
      "scikitlearn_data(data=\"load_boston\") -> load_iris for iris data etc.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r_0_0_read_sns_sklearn.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - Age\n",
      "      - Sex\n",
      "      - Body mass index\n",
      "      - Average blood pressure\n",
      "      - S1\n",
      "      - S2\n",
      "      - S3\n",
      "      - S4\n",
      "      - S5\n",
      "      - S6\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "data = r_0_0_read_sns_sklearn.scikitlearn_data('load_diabetes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  target  \n",
       "0 -0.002592  0.019908 -0.017646   151.0  \n",
       "1 -0.039493 -0.068330 -0.092204    75.0  \n",
       "2 -0.002592  0.002864 -0.025930   141.0  \n",
       "3  0.034309  0.022692 -0.009362   206.0  \n",
       "4 -0.002592 -0.031991 -0.046641   135.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow import e_0_2_describe_customized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>dtype</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nunique</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>163</td>\n",
       "      <td>100</td>\n",
       "      <td>141</td>\n",
       "      <td>302</td>\n",
       "      <td>63</td>\n",
       "      <td>66</td>\n",
       "      <td>184</td>\n",
       "      <td>56</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_nulls</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>perc_nulls</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-3.63962e-16</td>\n",
       "      <td>1.30991e-16</td>\n",
       "      <td>-8.01395e-16</td>\n",
       "      <td>1.28982e-16</td>\n",
       "      <td>-9.04254e-17</td>\n",
       "      <td>1.30112e-16</td>\n",
       "      <td>-4.56397e-16</td>\n",
       "      <td>3.86317e-16</td>\n",
       "      <td>-3.8481e-16</td>\n",
       "      <td>-3.39849e-16</td>\n",
       "      <td>152.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>median</td>\n",
       "      <td>0.00538306</td>\n",
       "      <td>-0.0446416</td>\n",
       "      <td>-0.00728377</td>\n",
       "      <td>-0.00567061</td>\n",
       "      <td>-0.00432087</td>\n",
       "      <td>-0.00381907</td>\n",
       "      <td>-0.00658447</td>\n",
       "      <td>-0.00259226</td>\n",
       "      <td>-0.00194763</td>\n",
       "      <td>-0.0010777</td>\n",
       "      <td>140.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mode</td>\n",
       "      <td>0.0162807</td>\n",
       "      <td>-0.0446416</td>\n",
       "      <td>-0.0309956</td>\n",
       "      <td>-0.0400993</td>\n",
       "      <td>-0.0373437</td>\n",
       "      <td>-0.00100073</td>\n",
       "      <td>-0.0139477</td>\n",
       "      <td>-0.0394934</td>\n",
       "      <td>-0.0181183</td>\n",
       "      <td>0.00306441</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>77.093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    age          sex          bmi           bp           s1  \\\n",
       "dtype           float64      float64      float64      float64      float64   \n",
       "nunique              58            2          163          100          141   \n",
       "num_nulls             0            0            0            0            0   \n",
       "perc_nulls            0            0            0            0            0   \n",
       "mean       -3.63962e-16  1.30991e-16 -8.01395e-16  1.28982e-16 -9.04254e-17   \n",
       "median       0.00538306   -0.0446416  -0.00728377  -0.00567061  -0.00432087   \n",
       "mode          0.0162807   -0.0446416   -0.0309956   -0.0400993   -0.0373437   \n",
       "std            0.047619     0.047619     0.047619     0.047619     0.047619   \n",
       "\n",
       "                     s2           s3           s4          s5           s6  \\\n",
       "dtype           float64      float64      float64     float64      float64   \n",
       "nunique             302           63           66         184           56   \n",
       "num_nulls             0            0            0           0            0   \n",
       "perc_nulls            0            0            0           0            0   \n",
       "mean        1.30112e-16 -4.56397e-16  3.86317e-16 -3.8481e-16 -3.39849e-16   \n",
       "median      -0.00381907  -0.00658447  -0.00259226 -0.00194763   -0.0010777   \n",
       "mode        -0.00100073   -0.0139477   -0.0394934  -0.0181183   0.00306441   \n",
       "std            0.047619     0.047619     0.047619    0.047619     0.047619   \n",
       "\n",
       "             target  \n",
       "dtype       float64  \n",
       "nunique         214  \n",
       "num_nulls         0  \n",
       "perc_nulls        0  \n",
       "mean        152.133  \n",
       "median        140.5  \n",
       "mode             72  \n",
       "std          77.093  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_0_2_describe_customized.describe_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow import e_5_0_corr_response_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "response='target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This module is to find correlation between data and response variable.\n",
      "This module is run only after one hot encoding is done.\n",
      "correlation(data, response, method=\"pearson\") -> data, response variable, ‘pearson’, ‘kendall’, ‘spearman’\n",
      "\n"
     ]
    }
   ],
   "source": [
    "e_5_0_corr_response_var.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    1.000000\n",
       "bmi       0.586450\n",
       "s5        0.565883\n",
       "bp        0.441484\n",
       "s4        0.430453\n",
       "s3        0.394789\n",
       "s6        0.382483\n",
       "s1        0.212022\n",
       "age       0.187889\n",
       "s2        0.174054\n",
       "sex       0.043062\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_5_0_corr_response_var.correlation(data, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow import e_6_0_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This module is to split the data set into train and test set\n",
      "random_split is to split the data randomly into a train and test set\n",
      "sequentil_split is to split the data sequentially into a train and test set\n",
      "TODO:research other ways train test split can be achieved\n",
      "X_train, X_test, y_train, y_test = random_split(data, response, test_size = 0.2, random_state=99)\n",
      "X_train, X_test, y_train, y_test = sequential_split(data, response, test_size = 0.2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "e_6_0_split.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = e_6_0_split.random_split(data, response, test_size = 0.2, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow import e_9_0_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This module is to find the principal components in the dataset\n",
      "There are four different methods used\n",
      "Specify them while passing to a function\n",
      "It is recommended that all numerical and categorical variables be standardized before passing\n",
      "these dimensionality reduction methods given below\n",
      "PCA,  FactorAnalysis,  IncrementalPCA,  KernalPCA\n",
      "dim_reduction(X_train, X_test, method = \"PCA\", n_components=3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "e_9_0_pca.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test = e_9_0_pca.dim_reduction(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# starts modeling - test all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from workflow import m_1_0_neural_network_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Model for Regression\n",
      "This module should include the most basic to the most advanced form of neural netowork model in keras\n",
      "TODO: Advanced Neural Networks\n",
      "optimizers: SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax,Nadam\n",
      "basic_model_classification(in_shape,total_hidden_layer,opt_func=\"Adam\",learning_rate=0.001,loss_func=\"mse\",metric=[\"mse\",\"mae\"])\n",
      "fit_model(X_train, y_train, model, batch_size=10, epochs=100, shuffle=True, verbose=2, validation_split=0.1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m_1_0_neural_network_regression.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = m_1_0_neural_network_regression.basic_model_classification(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 11\n",
      "Trainable params: 11\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 317 samples, validate on 36 samples\n",
      "Epoch 1/100\n",
      " - 0s - loss: 28399.1282 - mse: 28399.1230 - mae: 149.9620 - val_loss: 33268.9285 - val_mse: 33268.9297 - val_mae: 164.9697\n",
      "Epoch 2/100\n",
      " - 0s - loss: 28377.7361 - mse: 28377.7344 - mae: 149.8958 - val_loss: 33242.9125 - val_mse: 33242.9141 - val_mae: 164.8979\n",
      "Epoch 3/100\n",
      " - 0s - loss: 28352.5662 - mse: 28352.5684 - mae: 149.8175 - val_loss: 33212.7948 - val_mse: 33212.7969 - val_mae: 164.8120\n",
      "Epoch 4/100\n",
      " - 0s - loss: 28323.8843 - mse: 28323.8828 - mae: 149.7265 - val_loss: 33177.8408 - val_mse: 33177.8398 - val_mae: 164.7099\n",
      "Epoch 5/100\n",
      " - 0s - loss: 28291.1366 - mse: 28291.1387 - mae: 149.6233 - val_loss: 33140.2372 - val_mse: 33140.2344 - val_mae: 164.5997\n",
      "Epoch 6/100\n",
      " - 0s - loss: 28255.0569 - mse: 28255.0566 - mae: 149.5065 - val_loss: 33097.7827 - val_mse: 33097.7812 - val_mae: 164.4750\n",
      "Epoch 7/100\n",
      " - 0s - loss: 28215.6812 - mse: 28215.6758 - mae: 149.3781 - val_loss: 33051.8474 - val_mse: 33051.8477 - val_mae: 164.3396\n",
      "Epoch 8/100\n",
      " - 0s - loss: 28173.4196 - mse: 28173.4199 - mae: 149.2410 - val_loss: 33003.7139 - val_mse: 33003.7148 - val_mae: 164.1974\n",
      "Epoch 9/100\n",
      " - 0s - loss: 28128.8262 - mse: 28128.8203 - mae: 149.0951 - val_loss: 32952.3077 - val_mse: 32952.3086 - val_mae: 164.0454\n",
      "Epoch 10/100\n",
      " - 0s - loss: 28081.3799 - mse: 28081.3789 - mae: 148.9413 - val_loss: 32897.9399 - val_mse: 32897.9414 - val_mae: 163.8843\n",
      "Epoch 11/100\n",
      " - 0s - loss: 28031.5080 - mse: 28031.5039 - mae: 148.7766 - val_loss: 32840.2938 - val_mse: 32840.2969 - val_mae: 163.7135\n",
      "Epoch 12/100\n",
      " - 0s - loss: 27978.7299 - mse: 27978.7285 - mae: 148.6036 - val_loss: 32779.4383 - val_mse: 32779.4375 - val_mae: 163.5327\n",
      "Epoch 13/100\n",
      " - 0s - loss: 27923.3367 - mse: 27923.3398 - mae: 148.4196 - val_loss: 32715.6191 - val_mse: 32715.6172 - val_mae: 163.3430\n",
      "Epoch 14/100\n",
      " - 0s - loss: 27864.9341 - mse: 27864.9336 - mae: 148.2303 - val_loss: 32650.0486 - val_mse: 32650.0488 - val_mae: 163.1477\n",
      "Epoch 15/100\n",
      " - 0s - loss: 27804.4249 - mse: 27804.4199 - mae: 148.0312 - val_loss: 32580.8706 - val_mse: 32580.8711 - val_mae: 162.9412\n",
      "Epoch 16/100\n",
      " - 0s - loss: 27740.7532 - mse: 27740.7539 - mae: 147.8240 - val_loss: 32508.9728 - val_mse: 32508.9727 - val_mae: 162.7264\n",
      "Epoch 17/100\n",
      " - 0s - loss: 27674.6575 - mse: 27674.6562 - mae: 147.6059 - val_loss: 32433.9022 - val_mse: 32433.9023 - val_mae: 162.5014\n",
      "Epoch 18/100\n",
      " - 0s - loss: 27606.1678 - mse: 27606.1699 - mae: 147.3780 - val_loss: 32355.3352 - val_mse: 32355.3340 - val_mae: 162.2662\n",
      "Epoch 19/100\n",
      " - 0s - loss: 27535.4017 - mse: 27535.4062 - mae: 147.1392 - val_loss: 32273.5575 - val_mse: 32273.5547 - val_mae: 162.0205\n",
      "Epoch 20/100\n",
      " - 0s - loss: 27461.1748 - mse: 27461.1738 - mae: 146.8977 - val_loss: 32191.7994 - val_mse: 32191.7988 - val_mae: 161.7742\n",
      "Epoch 21/100\n",
      " - 0s - loss: 27385.7064 - mse: 27385.7070 - mae: 146.6462 - val_loss: 32105.2643 - val_mse: 32105.2637 - val_mae: 161.5137\n",
      "Epoch 22/100\n",
      " - 0s - loss: 27307.6926 - mse: 27307.6934 - mae: 146.3836 - val_loss: 32015.9723 - val_mse: 32015.9727 - val_mae: 161.2439\n",
      "Epoch 23/100\n",
      " - 0s - loss: 27226.6955 - mse: 27226.6934 - mae: 146.1147 - val_loss: 31925.4226 - val_mse: 31925.4238 - val_mae: 160.9700\n",
      "Epoch 24/100\n",
      " - 0s - loss: 27144.1390 - mse: 27144.1387 - mae: 145.8391 - val_loss: 31831.4040 - val_mse: 31831.4023 - val_mae: 160.6853\n",
      "Epoch 25/100\n",
      " - 0s - loss: 27058.4502 - mse: 27058.4453 - mae: 145.5559 - val_loss: 31735.6275 - val_mse: 31735.6250 - val_mae: 160.3945\n",
      "Epoch 26/100\n",
      " - 0s - loss: 26971.2513 - mse: 26971.2559 - mae: 145.2596 - val_loss: 31636.2990 - val_mse: 31636.2988 - val_mae: 160.0923\n",
      "Epoch 27/100\n",
      " - 0s - loss: 26881.2269 - mse: 26881.2266 - mae: 144.9607 - val_loss: 31535.2924 - val_mse: 31535.2910 - val_mae: 159.7845\n",
      "Epoch 28/100\n",
      " - 0s - loss: 26789.5831 - mse: 26789.5840 - mae: 144.6480 - val_loss: 31430.2323 - val_mse: 31430.2324 - val_mae: 159.4637\n",
      "Epoch 29/100\n",
      " - 0s - loss: 26695.1338 - mse: 26695.1328 - mae: 144.3297 - val_loss: 31324.0462 - val_mse: 31324.0488 - val_mae: 159.1390\n",
      "Epoch 30/100\n",
      " - 0s - loss: 26599.2210 - mse: 26599.2168 - mae: 144.0032 - val_loss: 31215.1923 - val_mse: 31215.1914 - val_mae: 158.8050\n",
      "Epoch 31/100\n",
      " - 0s - loss: 26500.9610 - mse: 26500.9590 - mae: 143.6697 - val_loss: 31103.9566 - val_mse: 31103.9590 - val_mae: 158.4635\n",
      "Epoch 32/100\n",
      " - 0s - loss: 26400.5128 - mse: 26400.5117 - mae: 143.3287 - val_loss: 30991.5757 - val_mse: 30991.5723 - val_mae: 158.1171\n",
      "Epoch 33/100\n",
      " - 0s - loss: 26299.2329 - mse: 26299.2363 - mae: 142.9768 - val_loss: 30874.3532 - val_mse: 30874.3535 - val_mae: 157.7553\n",
      "Epoch 34/100\n",
      " - 0s - loss: 26194.4493 - mse: 26194.4492 - mae: 142.6222 - val_loss: 30757.3574 - val_mse: 30757.3574 - val_mae: 157.3930\n",
      "Epoch 35/100\n",
      " - 0s - loss: 26088.1632 - mse: 26088.1641 - mae: 142.2639 - val_loss: 30640.9577 - val_mse: 30640.9590 - val_mae: 157.0317\n",
      "Epoch 36/100\n",
      " - 0s - loss: 25981.9512 - mse: 25981.9531 - mae: 141.8950 - val_loss: 30518.3343 - val_mse: 30518.3340 - val_mae: 156.6504\n",
      "Epoch 37/100\n",
      " - 0s - loss: 25871.7413 - mse: 25871.7422 - mae: 141.5210 - val_loss: 30396.3116 - val_mse: 30396.3125 - val_mae: 156.2702\n",
      "Epoch 38/100\n",
      " - 0s - loss: 25760.8383 - mse: 25760.8379 - mae: 141.1357 - val_loss: 30271.0713 - val_mse: 30271.0723 - val_mae: 155.8784\n",
      "Epoch 39/100\n",
      " - 0s - loss: 25648.9097 - mse: 25648.9141 - mae: 140.7416 - val_loss: 30141.5870 - val_mse: 30141.5859 - val_mae: 155.4730\n",
      "Epoch 40/100\n",
      " - 0s - loss: 25533.1948 - mse: 25533.1934 - mae: 140.3478 - val_loss: 30015.8607 - val_mse: 30015.8613 - val_mae: 155.0778\n",
      "Epoch 41/100\n",
      " - 0s - loss: 25418.2663 - mse: 25418.2656 - mae: 139.9446 - val_loss: 29883.7225 - val_mse: 29883.7227 - val_mae: 154.6615\n",
      "Epoch 42/100\n",
      " - 0s - loss: 25300.2552 - mse: 25300.2559 - mae: 139.5298 - val_loss: 29751.2477 - val_mse: 29751.2461 - val_mae: 154.2431\n",
      "Epoch 43/100\n",
      " - 0s - loss: 25181.1063 - mse: 25181.1055 - mae: 139.1140 - val_loss: 29616.4201 - val_mse: 29616.4199 - val_mae: 153.8163\n",
      "Epoch 44/100\n",
      " - 0s - loss: 25060.7573 - mse: 25060.7578 - mae: 138.6880 - val_loss: 29480.3892 - val_mse: 29480.3887 - val_mae: 153.3840\n",
      "Epoch 45/100\n",
      " - 0s - loss: 24938.4289 - mse: 24938.4297 - mae: 138.2595 - val_loss: 29343.9158 - val_mse: 29343.9160 - val_mae: 152.9488\n",
      "Epoch 46/100\n",
      " - 0s - loss: 24815.8557 - mse: 24815.8574 - mae: 137.8203 - val_loss: 29202.4025 - val_mse: 29202.4023 - val_mae: 152.4975\n",
      "Epoch 47/100\n",
      " - 0s - loss: 24690.1092 - mse: 24690.1074 - mae: 137.3786 - val_loss: 29063.6697 - val_mse: 29063.6680 - val_mae: 152.0526\n",
      "Epoch 48/100\n",
      " - 0s - loss: 24564.3141 - mse: 24564.3145 - mae: 136.9304 - val_loss: 28921.9179 - val_mse: 28921.9180 - val_mae: 151.5971\n",
      "Epoch 49/100\n",
      " - 0s - loss: 24437.7075 - mse: 24437.7070 - mae: 136.4726 - val_loss: 28776.7725 - val_mse: 28776.7715 - val_mae: 151.1293\n",
      "Epoch 50/100\n",
      " - 0s - loss: 24309.3586 - mse: 24309.3594 - mae: 136.0098 - val_loss: 28631.2944 - val_mse: 28631.2930 - val_mae: 150.6594\n",
      "Epoch 51/100\n",
      " - 0s - loss: 24178.9478 - mse: 24178.9473 - mae: 135.5486 - val_loss: 28487.5583 - val_mse: 28487.5566 - val_mae: 150.1930\n",
      "Epoch 52/100\n",
      " - 0s - loss: 24049.0949 - mse: 24049.0957 - mae: 135.0820 - val_loss: 28340.8822 - val_mse: 28340.8828 - val_mae: 149.7160\n",
      "Epoch 53/100\n",
      " - 0s - loss: 23917.4126 - mse: 23917.4141 - mae: 134.6067 - val_loss: 28192.6415 - val_mse: 28192.6426 - val_mae: 149.2321\n",
      "Epoch 54/100\n",
      " - 0s - loss: 23784.8354 - mse: 23784.8379 - mae: 134.1195 - val_loss: 28040.6207 - val_mse: 28040.6191 - val_mae: 148.7349\n",
      "Epoch 55/100\n",
      " - 0s - loss: 23649.8602 - mse: 23649.8633 - mae: 133.6291 - val_loss: 27890.7053 - val_mse: 27890.7051 - val_mae: 148.2419\n",
      "Epoch 56/100\n",
      " - 0s - loss: 23515.8092 - mse: 23515.8066 - mae: 133.1344 - val_loss: 27736.1457 - val_mse: 27736.1465 - val_mae: 147.7329\n",
      "Epoch 57/100\n",
      " - 0s - loss: 23379.1511 - mse: 23379.1523 - mae: 132.6359 - val_loss: 27584.2496 - val_mse: 27584.2500 - val_mae: 147.2307\n",
      "Epoch 58/100\n",
      " - 0s - loss: 23242.9986 - mse: 23243.0000 - mae: 132.1324 - val_loss: 27429.8847 - val_mse: 27429.8828 - val_mae: 146.7188\n",
      "Epoch 59/100\n",
      " - 0s - loss: 23104.9817 - mse: 23104.9805 - mae: 131.6255 - val_loss: 27275.1647 - val_mse: 27275.1641 - val_mae: 146.2033\n",
      "Epoch 60/100\n",
      " - 0s - loss: 22965.4486 - mse: 22965.4492 - mae: 131.1199 - val_loss: 27120.3719 - val_mse: 27120.3730 - val_mae: 145.6863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      " - 0s - loss: 22827.3883 - mse: 22827.3887 - mae: 130.5908 - val_loss: 26959.6858 - val_mse: 26959.6855 - val_mae: 145.1477\n",
      "Epoch 62/100\n",
      " - 0s - loss: 22685.2087 - mse: 22685.2090 - mae: 130.0680 - val_loss: 26803.5136 - val_mse: 26803.5137 - val_mae: 144.6215\n",
      "Epoch 63/100\n",
      " - 0s - loss: 22545.3155 - mse: 22545.3145 - mae: 129.5285 - val_loss: 26641.5822 - val_mse: 26641.5840 - val_mae: 144.0747\n",
      "Epoch 64/100\n",
      " - 0s - loss: 22402.3200 - mse: 22402.3203 - mae: 128.9936 - val_loss: 26480.5709 - val_mse: 26480.5703 - val_mae: 143.5295\n",
      "Epoch 65/100\n",
      " - 0s - loss: 22260.1943 - mse: 22260.1914 - mae: 128.4512 - val_loss: 26318.9804 - val_mse: 26318.9805 - val_mae: 142.9795\n",
      "Epoch 66/100\n",
      " - 0s - loss: 22116.5495 - mse: 22116.5508 - mae: 127.9070 - val_loss: 26157.0702 - val_mse: 26157.0703 - val_mae: 142.4270\n",
      "Epoch 67/100\n",
      " - 0s - loss: 21972.9118 - mse: 21972.9102 - mae: 127.3600 - val_loss: 25994.2925 - val_mse: 25994.2930 - val_mae: 141.8687\n",
      "Epoch 68/100\n",
      " - 0s - loss: 21827.6131 - mse: 21827.6133 - mae: 126.8088 - val_loss: 25833.8430 - val_mse: 25833.8438 - val_mae: 141.3159\n",
      "Epoch 69/100\n",
      " - 0s - loss: 21683.6262 - mse: 21683.6230 - mae: 126.2488 - val_loss: 25666.0701 - val_mse: 25666.0703 - val_mae: 140.7378\n",
      "Epoch 70/100\n",
      " - 0s - loss: 21536.8471 - mse: 21536.8477 - mae: 125.6803 - val_loss: 25502.0726 - val_mse: 25502.0723 - val_mae: 140.1684\n",
      "Epoch 71/100\n",
      " - 0s - loss: 21389.8608 - mse: 21389.8613 - mae: 125.1156 - val_loss: 25337.4071 - val_mse: 25337.4062 - val_mae: 139.5948\n",
      "Epoch 72/100\n",
      " - 0s - loss: 21244.6023 - mse: 21244.6016 - mae: 124.5339 - val_loss: 25167.9331 - val_mse: 25167.9336 - val_mae: 139.0027\n",
      "Epoch 73/100\n",
      " - 0s - loss: 21096.1801 - mse: 21096.1758 - mae: 123.9608 - val_loss: 25002.9722 - val_mse: 25002.9727 - val_mae: 138.4232\n",
      "Epoch 74/100\n",
      " - 0s - loss: 20948.8317 - mse: 20948.8320 - mae: 123.3811 - val_loss: 24835.7711 - val_mse: 24835.7715 - val_mae: 137.8338\n",
      "Epoch 75/100\n",
      " - 0s - loss: 20800.6949 - mse: 20800.6953 - mae: 122.7999 - val_loss: 24667.1020 - val_mse: 24667.1016 - val_mae: 137.2364\n",
      "Epoch 76/100\n",
      " - 0s - loss: 20651.8188 - mse: 20651.8223 - mae: 122.2088 - val_loss: 24497.9375 - val_mse: 24497.9375 - val_mae: 136.6354\n",
      "Epoch 77/100\n",
      " - 0s - loss: 20502.9200 - mse: 20502.9199 - mae: 121.6196 - val_loss: 24329.5539 - val_mse: 24329.5547 - val_mae: 136.0340\n",
      "Epoch 78/100\n",
      " - 0s - loss: 20354.1452 - mse: 20354.1445 - mae: 121.0279 - val_loss: 24161.7979 - val_mse: 24161.7988 - val_mae: 135.4317\n",
      "Epoch 79/100\n",
      " - 0s - loss: 20207.1990 - mse: 20207.2012 - mae: 120.4258 - val_loss: 23989.1492 - val_mse: 23989.1484 - val_mae: 134.8101\n",
      "Epoch 80/100\n",
      " - 0s - loss: 20056.2047 - mse: 20056.2031 - mae: 119.8282 - val_loss: 23823.4600 - val_mse: 23823.4609 - val_mae: 134.2096\n",
      "Epoch 81/100\n",
      " - 0s - loss: 19907.3965 - mse: 19907.3945 - mae: 119.2249 - val_loss: 23655.4346 - val_mse: 23655.4355 - val_mae: 133.5988\n",
      "Epoch 82/100\n",
      " - 0s - loss: 19758.5549 - mse: 19758.5527 - mae: 118.6193 - val_loss: 23482.3740 - val_mse: 23482.3750 - val_mae: 132.9674\n",
      "Epoch 83/100\n",
      " - 0s - loss: 19607.5306 - mse: 19607.5293 - mae: 118.0055 - val_loss: 23314.7743 - val_mse: 23314.7734 - val_mae: 132.3524\n",
      "Epoch 84/100\n",
      " - 0s - loss: 19459.2738 - mse: 19459.2754 - mae: 117.3853 - val_loss: 23141.2235 - val_mse: 23141.2246 - val_mae: 131.7127\n",
      "Epoch 85/100\n",
      " - 0s - loss: 19307.5564 - mse: 19307.5605 - mae: 116.7664 - val_loss: 22973.4271 - val_mse: 22973.4277 - val_mae: 131.0918\n",
      "Epoch 86/100\n",
      " - 0s - loss: 19158.7126 - mse: 19158.7168 - mae: 116.1400 - val_loss: 22799.9202 - val_mse: 22799.9199 - val_mae: 130.4458\n",
      "Epoch 87/100\n",
      " - 0s - loss: 19007.4260 - mse: 19007.4277 - mae: 115.5164 - val_loss: 22629.1428 - val_mse: 22629.1426 - val_mae: 129.8080\n",
      "Epoch 88/100\n",
      " - 0s - loss: 18858.7161 - mse: 18858.7168 - mae: 114.8888 - val_loss: 22454.4969 - val_mse: 22454.4980 - val_mae: 129.1523\n",
      "Epoch 89/100\n",
      " - 0s - loss: 18707.3951 - mse: 18707.3984 - mae: 114.2547 - val_loss: 22285.8628 - val_mse: 22285.8633 - val_mae: 128.5157\n",
      "Epoch 90/100\n",
      " - 0s - loss: 18557.6617 - mse: 18557.6602 - mae: 113.6269 - val_loss: 22115.8945 - val_mse: 22115.8945 - val_mae: 127.8706\n",
      "Epoch 91/100\n",
      " - 0s - loss: 18408.5730 - mse: 18408.5742 - mae: 112.9886 - val_loss: 21942.5136 - val_mse: 21942.5137 - val_mae: 127.2103\n",
      "Epoch 92/100\n",
      " - 0s - loss: 18257.8884 - mse: 18257.8887 - mae: 112.3464 - val_loss: 21772.4969 - val_mse: 21772.4961 - val_mae: 126.5593\n",
      "Epoch 93/100\n",
      " - 0s - loss: 18107.4904 - mse: 18107.4902 - mae: 111.7144 - val_loss: 21602.3288 - val_mse: 21602.3301 - val_mae: 125.9043\n",
      "Epoch 94/100\n",
      " - 0s - loss: 17958.2643 - mse: 17958.2617 - mae: 111.0661 - val_loss: 21430.2230 - val_mse: 21430.2227 - val_mae: 125.2385\n",
      "Epoch 95/100\n",
      " - 0s - loss: 17809.2210 - mse: 17809.2207 - mae: 110.4109 - val_loss: 21256.7089 - val_mse: 21256.7090 - val_mae: 124.5637\n",
      "Epoch 96/100\n",
      " - 0s - loss: 17658.8913 - mse: 17658.8906 - mae: 109.7599 - val_loss: 21086.7458 - val_mse: 21086.7441 - val_mae: 123.8993\n",
      "Epoch 97/100\n",
      " - 0s - loss: 17509.4011 - mse: 17509.4043 - mae: 109.1086 - val_loss: 20916.7790 - val_mse: 20916.7793 - val_mae: 123.2589\n",
      "Epoch 98/100\n",
      " - 0s - loss: 17360.5474 - mse: 17360.5469 - mae: 108.4424 - val_loss: 20744.7850 - val_mse: 20744.7852 - val_mae: 122.6149\n",
      "Epoch 99/100\n",
      " - 0s - loss: 17211.3061 - mse: 17211.3066 - mae: 107.7901 - val_loss: 20575.7902 - val_mse: 20575.7891 - val_mae: 121.9791\n",
      "Epoch 100/100\n",
      " - 0s - loss: 17064.5229 - mse: 17064.5254 - mae: 107.1260 - val_loss: 20402.4103 - val_mse: 20402.4121 - val_mae: 121.3238\n"
     ]
    }
   ],
   "source": [
    "m_1_0_neural_network_regression.fit_model(X_train, y_train, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow import z_0_2_mean_sq_err_corr_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This module will give a evaluation metrics for regression problem\n",
      "correlation, mean_absolute_error, mean_squared_error, mean_squared_log_error\n",
      "also use the module for correlation plot\n",
      "prediction_metrics(y_test, y_pred) will give data frame with all prediction metrics\n",
      "prediction_metrics(y_test, y_pred) plots actual vs predicted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z_0_2_mean_sq_err_corr_regression.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>1.449766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>metrics.mean_absolute_error</td>\n",
       "      <td>109.823253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>17604.247238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>median_absolute_error</td>\n",
       "      <td>96.823132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>r2_score</td>\n",
       "      <td>-2.015129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>explained_variance_score</td>\n",
       "      <td>0.049279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max_error</td>\n",
       "      <td>292.664249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pearson_correlation</td>\n",
       "      <td>0.605752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>spearman_correlation</td>\n",
       "      <td>0.631990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kendall_correlation</td>\n",
       "      <td>0.451118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Values\n",
       "mean_squared_log_error           1.449766\n",
       "metrics.mean_absolute_error    109.823253\n",
       "mean_squared_error           17604.247238\n",
       "median_absolute_error           96.823132\n",
       "r2_score                        -2.015129\n",
       "explained_variance_score         0.049279\n",
       "max_error                      292.664249\n",
       "pearson_correlation              0.605752\n",
       "spearman_correlation             0.631990\n",
       "kendall_correlation              0.451118"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_0_2_mean_sq_err_corr_regression.prediction_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z_0_2_mean_sq_err_corr_regression.corr_polt(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow import z_1_0_feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This module is to plot the feature importance of variables after random forest model\n",
      "pass in the model used, order of the column\n",
      "feature_importance_plot(model,col_order, n_top_features) -> n_top_features is the number of top features wanted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z_1_0_feature_importance.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-5f5bf456e8fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mz_1_0_feature_importance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importance_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\test_workflows\\workflow\\z_1_0_feature_importance.py\u001b[0m in \u001b[0;36mfeature_importance_plot\u001b[1;34m(model, col_order, n_top_features)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfeature_importance_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol_order\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_top_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mimp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mfeat_imp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_order\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Importance of Features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mfeat_imp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeat_imp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Importance of Features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "z_1_0_feature_importance.feature_importance_plot(model, ['a','b','c'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
